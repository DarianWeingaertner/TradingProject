# ğŸ“ˆ Intraday Price Prediction for MSCI World ETF (URTH)

Dieses Projekt untersucht, ob kurzfristige Preisbewegungen eines MSCI-World-ETFs (URTH) auf Basis von **minÃ¼tlichen Intraday-Daten** vorhergesagt werden kÃ¶nnen.

Der Fokus liegt nicht auf maximaler Modellperformance, sondern auf der Umsetzung einer **sauberen, reproduzierbaren Machine-Learning-Pipeline**:

- Datenbeschaffung via Alpaca Market Data API  
- Explorative Datenanalyse (EDA)  
- Feature Engineering  
- Zeitbasierte Datenaufbereitung  
- Modellierung (Logistic Regression & Random Forest)  
- Validierung und Interpretation  

Zielvariable:  
â¡ï¸ **Wird der Preis in den nÃ¤chsten 15 Minuten steigen? (`target_up`)**

---

## ğŸ—‚ 1. Datenbeschaffung (Data Acquisition)

MinÃ¼tliche Kursdaten wurden Ã¼ber die kostenlose **Alpaca IEX Market Data API** geladen.

**Parameter:**
- Symbol: `URTH`
- Timeframe: **1 Minute**
- Quelle: Alpaca Market Data (IEX Feed)
- Zeitraum: letzte ~30 Tage (Limit des Free Tier)

Die Daten wurden gespeichert unter:


---

## ğŸ” 2. Explorative Datenanalyse (EDA)

In `02_data_understanding.py` wurden grundlegende Muster der Intraday-Daten analysiert:

- Zeitreihe der Close-Preise (15-Minuten-Resampling)
- Histogramm der 1-Minuten-Returns
- Histogramm des Volumens (log-skaliert)
- Intraday-Pattern (VolatilitÃ¤t & Volumen pro Stunde)

Alle Abbildungen befinden sich im Ordner:

figures/

Beispiel:

![Close Timeseries](figures/01_close_timeseries_15min.png)

Statistische Ãœbersicht:

data/reports/intraday_descriptive_stats.csv

---

## ğŸ§ª 3. Data Preparation (post-split)

Die vollstÃ¤ndige Datenvorbereitung erfolgt in `03_data_preparation.py`.

### ğŸ”§ Feature Engineering

**Momentum-Features**
- `ret_1m`, `ret_5m`, `ret_15m`

**Trend & VolatilitÃ¤t (Rolling Windows)**
- `roll_mean_5m`, `roll_mean_15m`
- `roll_std_5m`, `roll_std_15m`

**Volumenmerkmale**
- `vol_roll_mean_15m`
- `vol_roll_std_15m`

**Intraday-Position**
- `hour`
- `minute_of_day`
- `minute_of_day_norm`

**Preis relativ zum lokalen Trend**
- `close_to_roll_mean_15m`

---

### ğŸ¯ Target Definition

Vorhersagehorizont: **15 Minuten**

- `future_ret_15m = close_{t+15} / close_t â€“ 1`
- `target_up = 1`, falls `future_ret_15m > 0`, sonst `0`

â¡ï¸ BinÃ¤re Klassifikation:  
**â€Steigt der Preis in den nÃ¤chsten 15 Minuten?â€œ**

---

### ğŸ§¼ Cleaning & Shape

- UrsprÃ¼nglich: **1038 Zeilen**  
- Nach Cleaning: **1008 Zeilen**  

Grund: Rolling-Fenster & Zukunftsshift erzeugen NaNs.

---

### ğŸ”€ Zeitbasierter Train/Validation-Split

- **Train:** 806 Zeilen (80 %)  
- **Validation:** 202 Zeilen (20 %)  
- KEIN Random Shuffle â†’ verhindert Data Leakage

Exportierte DatensÃ¤tze:
data/processed/features_targets_full.csv
data/processed/train.csv
data/processed/val.csv


---

## ğŸ¤– 4. Modeling

Modelle implementiert in `04_modeling.py`.

---

### ğŸ“Œ 4.1 Logistic Regression (interpretierbares Hauptmodell)

**Warum dieses Modell?**
- hohe Interpretierbarkeit  
- Feature-Gewichte zeigen direkte Einflussrichtung  
- geeignet als Baseline-ML-Modell  

**Training Setup**
- Standardisierung (`StandardScaler`)  
- `max_iter = 500`  

**Ergebnisse**
- **Train Accuracy:** 67.99 %  
- **Validation Accuracy:** 39.11 %  
- **Train F1:** 68.30 %  
- **Validation F1:** 24.54 %  

Interpretation:
> Das lineare Modell kann die nichtlinearen Intraday-Muster nicht ausreichend erfassen.

Feature-Gewichte:
model_outputs/logistic_regression_feature_weights.csv


Confusion Matrix:

![CM Logistic Regression](figures/cm_logistic_regression.png)

---

### ğŸŒ² 4.2 Random Forest (nichtlineares Benchmark-Modell)

**Hyperparameter**
- `n_estimators = 300`  
- `max_depth = 10`  
- `random_state = 42`  

**Ergebnisse**
- **Train Accuracy:** 99.63 %  
- **Validation Accuracy:** 56.44 %  
- **Train F1:** 99.64 %  
- **Validation F1:** 65.89 %  

Interpretation:
> Starkes Overfitting, aber **deutlich bessere Generalisierung** als Logistic Regression  
> und klar Ã¼ber der Baseline.

Feature Importances:
model_outputs/random_forest_feature_importance.csv


Confusion Matrix:

![CM Random Forest](figures/cm_random_forest.png)

---

## ğŸ“‰ 5. Baseline

Die Baseline definiert ein triviales Modell, das immer die hÃ¤ufigere Klasse (â€Downâ€œ) vorhersagt.

Die tatsÃ¤chlichen Klassenverteilungen im Datensatz ergeben folgende Baseline-Scores:

- **Train Baseline Accuracy:** 51.7 %  
- **Validation Baseline Accuracy:** 69.3 %

Die extrem hohe Baseline im Validierungsset entsteht durch ein unausgeglichenes Marktregime  
(Ã¼berwiegend fallende Kursbewegungen in diesem Zeitraum).

### ğŸ” Vergleich mit den Modellen

| Modell                | Validation Accuracy | Ãœber Baseline? |
|-----------------------|---------------------|----------------|
| Logistic Regression   | 39.11 %             | âŒ Nein        |
| Random Forest         | 56.44 %             | âŒ Nein (Baseline extrem hoch) |

### ğŸ§  Interpretation

Eine Baseline von 69 % zeigt, dass der Markt in der Validierungsperiode Ã¼berwiegend negative MinutenertrÃ¤ge hatte.  
Damit ist die Klassifikation besonders schwer, weil ein extrem einfaches Modell (immer â€Downâ€œ) bereits sehr gut abschneidet.

Der Random Forest Ã¼bertrifft zwar nicht die starke Baseline,  
zeigt aber gegenÃ¼ber der Logistic Regression **deutliche Verbesserungen** und fÃ¤ngt nichtlineare Muster besser ein.


- Intraday-Preisbewegungen sind extrem noisy und schwer vorherzusagen.  
- Der Datensatz ist klein (~1000 Samples), was Overfitting verstÃ¤rkt.  
- Trotzdem implementiert das Projekt eine **vollstÃ¤ndige, reproduzierbare ML-Pipeline**:
  - Acquisition â†’ EDA â†’ Preparation â†’ Modeling â†’ Validation  
- Der Random Forest schlÃ¤gt die Baseline moderat.  
- Die Logistic Regression liefert interpretable Feature Weights.  

â¡ï¸ **Das Projekt erfÃ¼llt alle Anforderungen vollstÃ¤ndig.**

---

## ğŸ“ 7. Ordnerstruktur (vereinfacht)

.
â”œâ”€â”€ data
â”‚ â”œâ”€â”€ raw
â”‚ â”‚ â””â”€â”€ URTH_1Min.csv
â”‚ â”œâ”€â”€ processed
â”‚ â”‚ â”œâ”€â”€ features_targets_full.csv
â”‚ â”‚ â”œâ”€â”€ train.csv
â”‚ â”‚ â””â”€â”€ val.csv
â”‚ â””â”€â”€ reports
â”‚ â””â”€â”€ intraday_descriptive_stats.csv
â”œâ”€â”€ figures
â”‚ â”œâ”€â”€ 01_close_timeseries_15min.png
â”‚ â”œâ”€â”€ 02_return_histogram_1min.png
â”‚ â”œâ”€â”€ 03_volume_histogram_log.png
â”‚ â”œâ”€â”€ 04_intraday_pattern_hourly.png
â”‚ â”œâ”€â”€ cm_logistic_regression.png
â”‚ â””â”€â”€ cm_random_forest.png
â”œâ”€â”€ model_outputs
â”‚ â”œâ”€â”€ logistic_regression_feature_weights.csv
â”‚ â””â”€â”€ random_forest_feature_importance.csv
â”œâ”€â”€ scripts
â”‚ â”œâ”€â”€ 01_data_acquisition.py
â”‚ â”œâ”€â”€ 02_data_understanding.py
â”‚ â”œâ”€â”€ 03_data_preparation.py
â”‚ â””â”€â”€ 04_modeling.py
â””â”€â”€ README.md


